\section{DECAS Theory}

\subsection{Classical Decision Theory}\label{subsec:ClassicalDecisionTheory}

Classical decision theory revolves around an agents choices which are influenced around the agents own preferences
and opinions. In short, classical theory can be described in the following way \cite{Steele2020DecisionTheory}:

\begin{itemize}
    \item \textbf{Preferences and prospects:} Revolves around the agents own preferences and opinions
    \item \textbf{Normative focus:} The agents criteria based on \textbf{preferences and prospects} under generic cirucmstances
    \item \textbf{Expected Utility (EU) Theory:} Under uncertain situations, the agent will choose the option with the highest expected values
\end{itemize}

% Tikz figure of classical decision theory with a header with the text "Classical Elements of Decision Making"
% And three boxes below with the text "Decision-making-process", "Decision-maker" and "Decision" respectively
% in a horizontal line, the header should be in a rectangle and the boxes should be in rectangles as well
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \tikzstyle{every node}=[draw, rectangle, minimum width=6cm, minimum height=1cm, text width=6cm, align=center]
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (A) {Decision-making-process};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (B) [right=of A] {Decision-maker};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (C) [right=of B] {Decision};
        \node[above=of B] {Classical Elements of Decision Making};
        % Draw the arrows
        \draw[->] (A) -- (B);
        \draw[->] (B) -- (C);
    \end{tikzpicture}
    \caption{Classical Elements of Decision Making}
    \label{fig:ClassicalElements}
\end{figure}

Figure \ref{fig:ClassicalElements} shows the steps of classical decision theory. The decision-making process as described
by Langley \cite{Langley1995OpeningStool}. 

Langley describes the decision-making process as a either structured or unstructured process.
The structured process is sequential and steps such as intelligence, design, choice, review and/or implementation.
While the unstructured process is a way of trying to find a solution to a problem without a clear path, this
often results in a iterative process defined as: define, diagnose, design and decide.

The decision-maker is the agent whom is making the decision. It is important
for the decision-maker to have a clear understanding of the domain 
of the problem and the decision-making process. This is because the role as 
a decision-maker is to evaluate the option which will return the highest value.

Finally, the decision is the result of the decision maker evaluating the 
options yielded by the decision-making process. 

\subsection{DECAS Theory explained}\label{sec:DECASTheory}

DECAS Theory, which stands for Decision-making process, dEcision maker, deCision dAta, analycticS. 
The theory aims to extend the classical decision theory explained in section
\ref{subsec:ClassicalDecisionTheory} by adding an two additional pillars to the 
decision-making process. The theory is based on the idea that the decision-making process
is not only influenced by the decision-maker, but also by the data and analytics.

% Tikz figure of DECAS theory with two headers "Elements of DECAS Theory" and "Classical Elements of Decision Making"
% And five boxes below with the text "Decision-making-process", "Decision-maker", "Decision", "Data" and "Analytics" respectively
% in a horizontal line, the header should be in a rectangle and the boxes should be in rectangles as well
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \tikzstyle{every node}=[draw, rectangle, minimum width=6cm, minimum height=2cm, text width=6cm, align=center]
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (A) {Data};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (B) [right=of A] {Analytics};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (C) [right=of B] {Decision-making-process};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (D) [right=of C] {Decision-maker};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (E) [right=of D] {Decision};

        \node[above=of B] {Elements of DECAS Theory};
        \node[above=of D] {Classical Elements of Decision Making};
        % Draw the arrows
        \draw[->] (A) -- (B);
        \draw[->] (B) -- (C);
        \draw[->] (C) -- (D);
        \draw[->] (D) -- (E);
    \end{tikzpicture}
    \caption{Elements of DECAS Theory}
    \label{fig:DECASElements}
\end{figure}

What DECAS Theory brings to the table is the idea that the decision-making process 
should not only be influenced by the data provided, which normal 
DDDM\footnote{Data-Driven Decision Making} also mentions, however it does not 
emphasizes it as much \cite{Divan2017Data-drivenMaking}. 

DECAS Theory proposes that the decision-making process should only be influenced 
form the data and analytics states, as show in figure \ref{fig:DECASElements}. 
However the last part \textit{Classical Decision Making} is still present, 
as the decision-maker is still the agent whom is making the decision.

The advantage of DECAS Theory is compared to an automated decision-making process,
is that possible wrong decisions can be avoided, this is because bias in the data used
or even a wrong calculation in the algorithm used in the analysis can be avoided. 

\subsection{Elements of DECAS Theory}

The two elements, data and analytics, are the foundation of DECAS. However the 
implementation of these steps are not laid out in the theory. This is because they
are up for the interested party to decide. How this thesis have choosen to implement 
the data and analytics steps will be explained in section \ref{sec:DataAndAnalytics}.


\section{Analyzing the Impact of DECAS on Data-Driven Decision Making} 
The examples provided in the article highlight both failure and success in data-driven decisions, suggesting that many failures could have been avoided by establishing theories, methods, and principles for data-driven decisions. Therefore, according to the text, the DECAS theory emerges as a solution to issues mentioned in the headlines above. The theory provides fundamental arguments to support data-driven decision making. We will look through three different cases.

\subsection{Claim 1: Enhancing Decision-Making with Data and Analytics}
The first case involves the Swedish PES. According to reflections on the case, it was concluded that the Swedish government's failure was primarily due to the elimination of the human element in the decision-making process, relying solely on machines. The source emphasizes that the human decision-maker cannot be excluded from this process because analytics and algorithms cannot substitute for the human mind. Instead, they should act as complementary or supportive elements.

In order to gain the most benefits and reach the best available decisions, a balance between the elements is crucial. Therefore, according to the source, if this balance could have been discovered when the PES planned the automation of its decisions, it would have realized the importance of the human element and potentially averted the failures observed. From the start, the aim should have been to improve the decision-making process instead of replacing it entirely with automation. By doing so, it could have reflected the successes seen in the ACC and the Dutch tax organization, where the emphasis was on enhancing decisions with technology, not replacing the human element.

Recognizing the importance of data as a fundamental component of data-driven decision-making can lead to greater caution in ensuring the correct analysis of the appropriate data.
The sources state that the theory does not guarantee success merely by including the five elements, many other contributing and external factors can affect decision making. However, when it comes to data-driven decision making, the five elements are a crucial part of it. Therefore, it is important to look closely at each element on its own and see how all the elements work together. 

\subsection{Claim 2: Achieving Optimal Decisions through Collaborative Rationality}
When it comes to the second claim, the main point is that when humans and machines work together, they can achieve “collaborative rationality”. The source further explained that results can be significantly improved when different elements work together, resulting in more efficient and better results than when each element works alone. The idea of collaborative rationality comes according to the source from the definition made by Innes and Bohler, which is based on Habermas’ concept of communication. The concept made by Habermas combines the strength of both humans and machines to solve problems as a team. 

Further, the source states that everybody involved needs to be well-informed and free to share their opinions. Therefore, techniques must be used to make sure that what they say is legitimate, clear, honest, understandable, and accurate, without hiding anything. It also means that everyone needs to understand their roles, responsibilities, and what is expected of them, with a big focus on being open.If this kind of teamwork got thoroughly investigated, this could lead to finding an ideal decision-making, which until now has been hard to achieve due to limiting the individual reasoning and settling for good enough solutions.The source argues that if the PES had this theory beforehand, they could have realized that making the best decision does not just mean making it fully automatic. Instead, they should have made the humans, and the machines work together, and with the teamwork, they could have reached a higher level of rationality, which cannot be reached by singling out just one component. 

There are a lot of traits such as judgment, perception, intuition, emotions, understanding, and common sense which cannot be replicated by machines with “artificial intelligence”. 


As mentioned earlier, combining the human and the AI components can improve decision making but it requires many considerations. AI can make hard-to-grasp assets easy to use by collecting, sorting, and distributing information to improve decisions. AI also has the ability to easily look through large amounts of data quickly, but the human is needed to understand the findings made by the AI. In other words, turning information into knowledge and tackling the “so what” questions.


\subsection{Claim 3: Enhancing Decision-Making Through Integration of the Five Pillars}

Lastly, the theory’s final point looks at combining the five key elements also known as the five pillars of data-driven decision-making. The result of combining the elements is that it can lead to choosing the right analytics methods and techniques for the dataset you want to analyze. The source explains that combining the five elements can provide the decision-maker who is well-informed and knowledgeable with several benefits, such as a wider range of possible actions, improved forecasts of external events and their impacts, deeper understanding of outcomes through uncovering insight hidden in the data, enhanced models for predictions and finally more evidence and criteria for picking the best option. In other words, this approach makes the decision making better than one made without using any of the five elements.

As mentioned earlier PES failed to incorporate the human aspect of decision making, leading to poor-quality decisions. However, if they or others like them, would have understood the importance of this argument. They would have seen that the purpose of data and analytics is to provide the human decision maker with information at every stage of a well-defined decision-making process.

What this does is it provides a clearer understanding of the actions, events, outcomes, and rewards involved in traditional decision-making by merging a wider range of collective factors and information than an individual could alone. Therefore, adopting this theory could have prevented many organizations, governments, and corporations from making poor choices from the start, rather than addressing the consequences later on.


Lastly, by using DECAS in the case of New Zealand’s ACC, they managed to avoid failure by including the human element and not solely relying on the machine. When it came to decision-making was restricted to analyzing the data and acting as a support, meaning it did not act as a substitute for human judgment. The source continues to explain that the decision-making process was well-defined and continued to be followed, this also includes the algorithms. Despite this case not displaying the full potential that can be reached through proper data-driven decision-making, it still supports this argument that the five elements need to be integrated, and, finding the right balance among them is crucial.


\section{What-Why-How Framework} \label{sec:WhatWhyHow}

The What-Why-How Framework was developed by Tamara Munzner whom have written
a number of books in the field of data visualization. \cite{T2023VisualisationBookshelf} 

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \tikzstyle{every node}=[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center]
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (A) {What};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (B) [right=of A] {Why};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (C) [right=of B] {How};
        \node[above=of B] {What-Why-How Framework};
        % Draw the arrows
        \draw[->] (A) -- (B);
        \draw[->] (B) -- (C);
        % C loop back to A
        \draw[->] (C) to [out=-75,in=-100] (A);
    \end{tikzpicture}
    \caption{What-Why-How Framework}
    \label{fig:WhatWhyHow}
\end{figure}

\subsection{The What}

The \textit{What} in figure \ref{fig:WhatWhyHow} describes the end user will 
see or what will be feed into the visualization. The key points described are
\textit{Data Types} and \textit{Dataset Types} \cite{Munzner2015VisualizationDesign}.

The \textit{Data Types} are the values to be analysed, this for example could be

\begin{itemize}
    \item Items
    \item Attributes
    \item Links
    \item Positions
    \item Grids
\end{itemize}

The \textit{attributes} are the values of the items, these attributes have their own two attribute types.
It is either \textit{Categorical} or \textit{Ordered}. Categorical means that the values can be identified
by a category. For example, the color of a car. Ordered means that the values can be mesured in different ways. 
Munzner describes ordered as either \textit{Ordinal} or \textit{Quantitative}.
Ordinal could for example be the size of something, while quantitative could be the time until the car runs 
out of fuel.

Manzners visual representation of this step can be seen in appendix \ref{app:www-what}.

% Figure with five boxes, each box should have the headers
% "Tables", "Networks and Trees", "Fields", "Geometry" and "Clusters, Sets, Lists"
% Inside these boxes there should be the following: 
% Inside "Tables" there should be the text "Items" and "Attributes"
% Inside "Networks and Trees" there should be the text "Items (nodes)", "Links" and "Attributes"
% Inside "Fields" there should be the text "Positions" and "Grids" and "Attributes"
% Inside "Geometry" there should be the text "Items" and "Positions"
% Inside "Clusters, Sets, Lists" there should be the text "Items"

\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \tikzstyle{every node}=[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center]
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (A) {Tables};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (B) [right=of A] {Networks and Trees};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (C) [right=of B] {Fields};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (D) [right=of C] {Geometry};
        \node[draw, rectangle, minimum width=2cm, minimum height=1cm, text width=2cm, align=center] (E) [right=of D] {Clusters, Sets, Lists};
        % A
        \node[below=of A] (A1) {Items} ;
        \node[below=of A, yshift=-1.2cm] {Attributes};
        % B
        \node[below=of B] (B1) {Links};
        \node[below=of B, yshift=-1.2cm] {Attributes};
        % C 
        \node[below=of C] (C1) {Grids};
        \node[below=of C, yshift=-1.2cm] {Position};
        \node[below=of C, yshift=-2.4cm] {Attributes};
        % D
        \node[below=of D] (D1) {Items};
        \node[below=of D, yshift=-1.2cm] {Positions};
        % E
        \node[below=of E] (E1) {Items};
        % Lines form Top to first row
        \draw[->] (A) -- (A1);
        \draw[->] (B) -- (B1);
        \draw[->] (C) -- (C1);
        \draw[->] (D) -- (D1);
        \draw[->] (E) -- (E1);
    \end{tikzpicture}
    \caption{Data Types}
    \label{fig:DataTypes}
\end{figure}


\textit{Dataset Types} are the way the data types \textit{relate} to 
one another, examples of this can be seen in figure \ref{fig:DataTypes}. 
The dataset types can be ordered in different directions, like sequential, diverging or cyclic.

\subsection{The Why}

The \textit{Why} describes the \textit{Actions} and \textit{Targets} of the visualization.

In this step, we decide on what \textit{actions} we need to take and what would be beneficial to the end user.
We could analyze the data, either by consuming or by prodcuing it. We could also search for known or unknown patterns
in the data. An other option would be to query and comparing and return a summary \cite{Munzner2015VisualizationDesign}.

\textit{Targets} are the goals of the visualization. If we look at the whole dataset, we could be looking for
trends, outliers or features. We could also be looking for a specific item or a specific attribute, by analyzing either 
the distribution or the extremes. Or if we are looking on many attributes, we could se how they depend on each other, how they
correlate or their similarity.

For network data, an interesting factor is the topology and paths of the network. 

Manzners visual representation of this step can be seen in appendix \ref{app:www-why}.

\subsection{The How}

The \textit{How} is about how the visualizations and interactions with 
the data are designed. 

First is how we \textit{encode} the data. The first step is to \textit{arrange} the data, this can be done in a number of ways for example
we could use a timeline, plot a chart as separate items, ordered or aligned. And
we could also apply it to real world things, like plotting locations on a map.

We also need to map the data. This is based of categorical and ordered attributes. 

% Table with subtables for ordered and categorical
% Categorial have hue and shape
% Ordered have saturation, luminance, size, angle, curvature and motion
\begin{table}[h]
    \centering

        \begin{tabular}{|c|c|}
            \hline
            \textbf{Categorical} & \textbf{Ordered} \\
            \hline
            Hue & Saturation \\
            Shape & Luminance \\
            & Size, angle, curvature etc \\
            & Motion (Direction, rate, frequency etc) \\
            \hline
        \end{tabular}

    \caption{Encoding Data}
    \label{tab:EncodingData}
\end{table}

It is also important how the user can \textit{manipulate} the data. Should the user be able 
to change the representation of the data, select an item or attribute for more information, or 
navigate around different parts of the data. 

The \textit{How} is also about how to \textit{facet} the data. One option is to 
\textit{juxtapose}, meaning showing to tables side by side, or \textit{partition} the data by splitting
a table into smaller tables.
Another way is to \textit{superinpose}, meaning combining two tables into one.

Finally we need to be able to reduce the data. This is possible in three different ways.
We can \textit{filter}, \textit{aggregate} or \textit{embed} the data.
\textit{Filter} means to remove data based on one or several conditions. 
\textit{Aggregate} means to combine data into a smaller set.
\textit{Embed} means to show the data in a smaller space with the ability to expand.

Manzners visual representation of this step can be seen in appendix \ref{app:www-how}.

\subsection{The iterative process}

The What-Why-How model is an iterative process, while one interation could be satisfactory for 
smaller projects and organizations it could be beneficial to iterate over the process.
This means that we can start over with the \textit{What} and the current implementation, and 
see if we can improve upon the \textit{Why} and the \textit{How}.

\section{Data Analysis}\label{sec:DataAndAnalytics}